# 11 - Monitoring Operations


> "To improve is to change; to be perfect is to change often."
>
> ~ _Winston Churchill_

---

## The Metrics Mindset


To control our applications in the wild we must gain a thorough understanding
of how they behave. A system is designed to operate in a certain way but is it
really doing what we expect? Monitoring is how we find out. Our desire is to
get an accurate picture for how the application functions in live usage. This
is different than static analysis which looks for issues in the code itself.
Monitoring is about watching what is happening in the real world and detecting
patterns that require attention.

Leverage requires a deep system understanding. Measuring things is the fastest
way to gain that understanding. Observing the system in operation and
extracting data can yield profound insights. It can also validate or refute
our assumptions and beliefs. The scientific mindset enables us to make hypotheses
and experiments in order to better study the system.

Our goal is to ensure that everything is running exactly as we intended. Even
in a small system this will entail checking several hundred things
continuously. Obviously this can't possibly be done manually so instead we
invest in automation to monitor everything that we care about.

Adding telemetry to your applications is the first step. With high level
languages or environments it is very simple and cheap to add an embedded web
server. You can report point-in-time information such as loaded libraries,
interesting configuration parameters, rates, and counts. This enables you to
directly probe the application for its current state. If done in a standard
way, it provides a basic way of enabling distributed monitoring. As you scale,
you can replace this simple monitoring framework with more scalable
capabilities built on something like Apache Kafka.


### Test What You Care About Continuously

Each tap point for monitoring can be built using the same patterns as the test
cases that we built in the chapter on testing. We will use the diff test
framework to check every test against the approved answer. This makes it
extremely easy to write and maintain tests. Every test case should be one or
two lines of code.

Here are some examples of the types of tests.  Even without knowing anything
about the problem domain or implementation language these scripts are easy to
read and understand.

```python

def check_disk_space():
    system ('df | ok_space')


def temp_files():
    system ('find | limit_lines 1800 2000')


def reports_filed():
    from reports import report_count
    num_reports = report_count()
    if num_reports < 100:
        print("Not enough reports "+str(num_reports))


def process_running():
    system("ps -ef | grep apache | line_count 2" )

```


### Bad Events Should Trigger Automatic Escalation

The diff testing framework will save many hours in constructing new tests.
Instead of carefully thinking through what should happen, you can build test
cases that generate output. Then you can decide if the current answer is
acceptable. You can also let tests be extremely noisy at first and then
silence them selectively to ignore irrelevant output.

This lets you spend effort on the things that need attention and ignore all of
the things that produce the same stable output for every run. The
effectiveness of this approach in the real world can't be overstated. Every
test can be created in less than five minutes and repeated failures can also
be addressed quickly. The only tricky part is transporting results to a
general remote monitoring station. A simple solution for notification of
escalation events can save a lot of time.

Every condition that needs attention should get it. No failing tests should be
ignored. False positives are typically fixed by filtering the results of the
monitor or broadening some constraints before the check is being done. A
common design pattern is to make all tests only output exceptional behavior.
All test cases would be written to remain completely silent in the healthy
case and only generate output that requires attention.This is not required but
may work well for you.

Often, exceptional behavior requires tracking trends and baselines. Tools can
compare current results with expected results to look for patterns related to
typical behavior. Appropriate behavior may be related to situational
variables, such as time of day or user load.

In practice you will produce well over a thousand test cases. I recommend
caching the results of long running tests. This allows you run the tests often
without an undue burden being placed on the system. Only occasionally will the
long running tests be executed. Most often the cached result will simply offer
up the last answer. Note that failing test answers are not cached so that
failing tests are run repeatedly until they pass.

Strive to have the monitored application report its cached "result". It is in
the best position to manage that information. This works really well if the
transport is cheap and telemetry is well designed. The burden of analyzing
data is the responsibility of a third-party app. Collecting this sort of data
every several minutes isn't that burdensome for the app but it is best to
avoid designing complex monitoring stations that talk directly to your app.


### Operational Failure Should Result In New Test Conditions

No system is perfect - there will be situations that happen and are missed by
the current test cases. Every time this occurs it indicates a testing
weakness. Your testing boat has a hole in the hull. Patch it soon so that
when the problem recurs you will detect it immediately.

Over time your system will become very robust. It will be constantly
monitoring a large number of issues. Occasionally something will happen and an
alarm will go off but most of the conditions will remain silent. When
something does go wrong you will be the first to know. You will have an
advanced early warning system that will tell you what you need to do and where
you need to look first.


### Do Not Ignore System Errors Or Warnings

For your system to increase in quality you must respond to the issues that
need attention. Robustness is built simply by fixing every problem that occurs
and building additional monitoring each day. Monitoring is a lifestyle that
prevents problems by addressing weaknesses before they cascade into something
more serious. A small hole that is patched today can prevent a giant hole
later.

Be sensitive to the smallest symptoms and don't be hasty in silencing
complaints from your system monitors. Files created at the wrong time or
transactions not processing may not be a problem but they may indicate an
unexpected behavior that could be the first indication of a serious issue that
will cause problems later. Respond to the pre-detection in order to prevent
emergencies.


## Instrumentation and Logging

Build a standardized logging facility to record each call to strategic
functions within your code. Think through how to best use the logging system.
What are the best ways to format your messages, provide app-specific message
fields, and to delimit the data. Thinking about these things ahead of time
will simplify your life tremendously and give you a head start if you
eventually move to a log analysis and data mining tool like Splunk or
Elasticsearch.

Think of your logging capability as video surveillance for the traffic. It
allows you to find control and data flow issues when things go wrong. It also
lets you see the sequence of events in healthy operation. Logging can give you
tremendous insight into your software with minimal effort.

Be strategic about the tap points you select for logging. Each module has a
primary entry point that is the gateway to its core functionality. This is an
excellent point to place a sentinel. Log all of the traffic through this
gate. Log the time, primary function, and key parameters. This will let you
construct the story at the interface later.


### Put Instrumentation in Each Layer

Your architecture is undoubtedly built in layers. There are operating system
services that support the generic tools, frameworks, general purpose libraries
that serve the business needs of your domain, and application services that
meet the very specific needs of the current product.

Build separate logs for each layer of the entire system. Utilize 'logrotate'
or a similar mechanism to manage when the current files are swapped out and
how the older files are named. Build a mechanism to manage the data in such a
way to easily reconstruct a history of past events.


### Record All Interesting Data

The data that is recorded from the logger is typically time sensitive so most
entries start with a date stamp. Another popular choice is to record counts of
things. It is often useful to watch transaction frequencies and latencies and
queue levels in real time. A simple stats class can be used to accumulate
counts and then record the statistical information with each hit to the log.

By gathering individual sample info we can easily calculate the min, max, and
average values of the set. This is very useful for building an understanding
of the way the system operates. A simple bucket sort is useful for gathering
the samples.


### Unified Data Handling

Each time a function is called a log entry is generated. This entry can either 
be placed in a database table or appended to a file. For higher transaction 
levels more elaborate designs are required to batch up the data and efficiently
write it to permanent storage. Start with something simple but adapt to the 
true business needs as they grow.

If you are logging data at 50,000 transactions per second you have completely
different needs than at one transaction per second. Build your logging to
match the actual demand levels.  Logging is just like any other part of your
system, the goal is to be as simple as possible while still addressing the
fundamental demands.


### Troubleshoot Complex Problems

When problems occur, your logging system can be used to reveal the underlying
cause. Special tools can be written to look through the raw log data to find
patterns. By scanning the execution history you can identify the underlying
sequence of events. The simple nature of the log entries makes it easy to
construct tools to answer specific questions using regular expressions.
Consider writing tools that have a state machine to detect sequences within
your log files representing failure modes in your system.

The log data can be a treasure trove for analysis and experimentation. In more
complex scenarios, commercial tools can be very useful. These tools record,
analyze, and report on the logged data and contain detection for a wide
variety of failure modes. They also are capable of providing great reports of
the operational characteristics of your system.


### Logger Load

Because your logger is running as an integral part of every operation it is
important that it be efficient. Be careful to avoid the Heisenberg problem,
whereby the testing alters the behavior of the system. Make sure that your
logging isn't placing an unwanted delay on every transaction. The
performance impact of logging should be assessed early in the development
cycle. Consider implementing logging as a closure, if your language supports
it. This will allow you to be liberal with your logging while minimizing the
cost of constructing the log lines if they aren't needed at the requested
log level.

For simple monitoring needs I recommend starting with a simple custom
solution. A few lines of logging code may be all that you ever need to support
your overall project goals. As your needs get more demanding you can evolve
this simple system into something more sophisticated. Eventually you might
want to replace the entire system with a commercial system that offers high-
efficiency recording, analysis, and reporting tools.


## Analytics and Dashboards

Create a dashboard to make it easy for everyone involved with operations to
see the high-level picture. A dashboard should be easy to read and give you an
indicator of health within a few seconds. Many groups rely on personal
conversations and reports but this approach is error prone and requires human
effort. These conversations and hand-generated reports can be easily replaced
by an automated dashboard. The cheapest dashboard can be a simple embedded web
server serving up telemetry on demand.


### Project Dashboard

The dashboard doesn't need to be complex to be useful. For example, imagine a 
set of scripts that automatically generates the following text file on a shared 
server:


|--------|---------|------------|----|
| **Issues** | 15 Open | 100 Closed||
| **Source** | 20,888 Lines | 300 Files||
| **Test** | 102 Tests |  85% Coverage | 23% source/test|
| **Complexity** | 10200 Overall |||
| **Complex Modules** | 90 Rubilator | 67 Framistance | 50 Security|
| **Last Month** | 23/100 Issues | 18000/270 Source ||


The dashboard should be updated automatically. Make sure everyone has access
to it and make it the focal point of all progress meetings. It is all too easy
for discussions about progress to turn into anecdotes about what people are
intending to do rather than a discussion of actual accomplishments. Inspire
healthy competition within the team to "beat the numbers".

Allow everyone on the team to make suggestions for improvements. Respond to
suggestions for improving the metrics. Often, other engineers and managers
will have strong opinions about what you are measuring and how that data will
affect their lives. Listen to their opinions and incorporate their ideas into
each iteration.

Numbers are not a substitute for true understanding and judgment. Be sensitive
to how the data is used and its human impact.  Our goal is
to build opportunity for everyone so this should be a motivating and energizing
task for everyone. 

Prefer quantitative data. Sound business decisions are supported by data that
is gathered directly from the trenches. In the absence of real data, the
strategic planners are likely to resort to wild assertions and crazy ideas.
Build data that makes decisions easy.


### Gather The Data Regularly

All of the data gathering should be fully automated. Build scripts that gather
all of the information at a reasonable time interval. If the data collection
is cheap enough then it can be gathered frequently, while more expensive  data
can be gathered less frequently. Make sure the data collection is as automated
as possible, otherwise it will be neglected at some point.

Scale requires you to flip monitoring on its head. In these situations
applications push reports and monitoring stations subscribe to measurements
that they are interested in tracking. Telemetry flows continuously through a
bus and monitoring stations can then pick what is interesting.

Count many different things. Record latencies, throughputs, queue depths,
number of records, and other types of volumes throughout the system. For each
of these attributes, think of the healthy range that represents normal
operation. Set thresholds for each attribute. Report the range violations as
an early warning alert. These alerts can be used to identify problems before
they have even happened.

Counts beyond the expected range can trigger escalation to operations.
Exception-based Monitoring focuses attention on the critical areas. Pattern
matching can also be used to watch a combination of conditions to provide even
more sophisticated warnings. If you are watching a thousand different
conditions in real time and ten are in a warning state then you can rest easy.
990 conditions are totally nominal allowing you to investigate the remaining
ten. This will give you a deep understanding of your overall system. Just
investigating the pre-warning alarms will let you control your system at a
level that few operations ever achieve.


### Design Dashboards

Design your entire monitoring strategy to support your business. What do you
need to control the most in your system? Build your monitoring around those
needs by making sure they are represented in your dashboard. Make the key
metrics highly visible to everyone. When the values start to creep outside the
acceptable range alarms should go off.

If you are monitoring a thousand different things do not show a list of all of
the things being monitored. Instead, use top-n reporting to show the items
that currently need attention. Build different severity levels for different
conditions. Allow people to monitor errors, warnings and informational
attributes with different parts of the UI. Some people will only be interested
in errors and there should be an escalation path that just shows that.


### Notification System

Design a notification system to provide a method for escalation of the most
critical issues. Some issues demand immediate attention and must be sent to
the responsible parties immediately. Email and text notifications should be
reserved for critical issues and other issues can flow through the web
dashboards.

You can easily build your own notification system using tools like Amazon
Simple Email Service (SES) or Google App Engine Mail API. Or use commercial
systems to provide the sending capability. SendGrid, Mailgun and Mailjet may
be worth looking at for a general solution. You can also use tools like
[SNAP](https://www.ca.com/us/lpg/Nimsoft-Monitor-
Snap/Register.aspx?mrm=469077)  from C.A. Technologies to build your
notification system. Seek to strike a balance between simplicity and meeting
your specific business needs.


## Measurements Drive Decisions

Metrics will drive behavioral change. You should spend some time researching
the area of greatest need for change. Avoid random measurements that don't
really matter to you. If you are starting a new metrics collection it is
important that you start with the most critical things first.

Collect the data to quantify your core development process capabilities or the
quality of the product itself. Metrics related to the development process and
software product should be the initial focus. Collect the numbers that best
illustrate what quality looks like.

Be careful not to sabotage your data collection. I've been involved in a
number of data collection projects that met immediate resistance because it
wasn't clear why data was being collected or how it would be used. Engineers
are naturally suspicious about how data might be used against them so be
sensitive.

Start with low-hanging fruit. What data do you already have access to? What
data could you easily collect with a 20-line Python script? Would this data
give you insight?  If so, grab it and use it. Almost everyone has access to
issue  counts, line counts, tests passing, etc. Use what you have and continue
to build more.


### Baseline, Trend, and Goals

Create a baseline by selecting a metric that determines what normal looks
like. If you have previous data you may be able to leverage that knowledge to
calibrate a baseline. If you don't have adequate data, it's not a problem.
Once you start looking at any number consistently you will develop a feeling
for good and bad.

Question the initial numbers and don't take anything for granted. Validate the
measurements and ask questions about why the data looks the way it does.
Remember that the true quest is for deeper understanding, not just pretty
graphs. Propose a plan for possible improvements. Think about how th knowledge
you've gained could be used to take your project to the next level. Metrics
aren't the final answer, as much as they are a source of new questions.

Validate your approach with others. This is a chance for you to engage the
rest of the organization in a larger discussion about software development.
Show others your early data and gather their opinions about where you should
look next. Allow collaborators to influence your direction and contribute
ideas to the project.


### Experimentation and Quantifying Results

The goal of experimentation should be to figure out what works and what
doesn't. The metrics give us a feedback loop. Determine how to best test the
affects of possible changes. Design an experiment to test a hypothesis or
validate an assumption.

After the test is in place apply a desired change and study its impact. For
example, we may believe that high complexity lowers productivity. This requires
measuring both complexity and productivity. It may take several iterations to
get a good complexity measurement or a productivity metric. As a result of this
work, you will have a far deeper understanding of, not only complexity and
productivity, but the interactions between the two.

Next, establish operational rules that are customized to the needs of your
organization. Commit to a process of positive changes that are driven by
empirical evidence. Step back and take a longer view by examining the bigger
picture for your development projects. What are your biggest unmet business
needs? Where are you able to excel in areas where other groups struggle? When
do you stumble and how can you improve to have better results? Are you moving
in the direction you want? Think about where you will be a year from now.
Where were you a year ago?

The software industry is rapidly advancing and changing. There is a coming labor
shortage that will catch many companies by surprise. What does the actual data
teach you about your organization? Will you be able to attract top talent in an
environment where engineers can have their pick of places to work?

Companies that build a robust development capability will produce far more and
have an attractive work environment. Measurement can be at the heart of your
ability to build a world-class software company. Organizations that run repeated
death marches due to poor planning will fail in the next decade because they
will be unable to staff their projects.

Many organizations measure random things without a clear view of what they are
trying to accomplish. This is a lot like engineers making random changes to a
complex system hoping to fix a bug without really understanding how it all
works. In both cases, we need to disassemble the system to examine each part
in isolation.

Start with the overall goal, then figure out which measurable attributes you
can observe. Understanding the fundamentals will help you optimize them and
design a path for improvements. Steer the larger effort by conducting small
experiments to validate your assumptions.

Testing is the key to software process improvement. If you can think of an
idea and a way to measure the results, you can validate that you are making
positive improvements. Testing also gives you evidence that your improvement
is real. Then you can lobby for broader adoption with confidence.


### Drive Business Decisions

Some organizations collect data without a clear plan of how it will be used.
Collecting metrics is really only valuable if you use the data to change how you
do business. Metrics should always be used as part of a bigger plan to improve
your software processes. Make reviewing the metrics a key part of any business
review. Find the most compelling numbers and concentrate on them.

Be selective about the metrics you gather. Gathering a few key numbers should
be more than sufficient to answer the fundamental questions. Communicate the
decisions in terms of the measured results. The focus of measurement is
improvement, enabled by better understanding.


### Essential Project Metrics

There is no standard set of metrics that will work for every organization so the
goal is to calibrate the metrics for your development team. What works for one
group will be a danger signal for another. Figure out the most critical measures
for your team at this moment. Starting with too many metrics will generate
confusion and undermine the overall effort.

Once you have selected the values to record, you need to figure out how to
collect the numbers automatically. Avoid any metrics that require a person to
record data. A skilled Python programmer can write a tool to collect almost
anything in about an hour.

The next step will be to calibrate the baseline. If you are just starting out
collecting data, I recommend that you defer creating any basic rules until you
have been collecting values for a while. Start by measuring the current reality
and then apply judgment later.

The absolute values mean little but the trends are important. Until you have
collected a lot of data over time you can't speculate that 100 defects or 20
tests is good or bad. Remember, you are looking for changes to understand more
about your ability to successfully create software.

Abandon metrics that don't seem to yield actionable insight and expand the
metrics that you find useful. Create finer-grained resolution on the
quantitative data. Create a competency related to collecting and using data to
foster improvement. The following lists gives an overview of possible metrics.
You may want to start by selecting a subset of these items to measure.


**Issues**

Problems surface during the course of a project and should be logged so that
they can be tracked by the team. The issue tracking system can be mined for
relevant information about the status of the project and what areas need the
most attention.

Consider developing a simple set of scripts that interrogate your issue
tracking system and supply counters on specific areas. These types of tools are
very easy to build and access to the tool implementation makes it simple
to adjust to the changing needs for information throughout the course of your
project. Here's a sample list of issues to measure:

* Features to be implemented
* Features to be defined
* Architecture and design issues
* Failing tests and defects
* Defect finding rate - Hours of testing to find the next defect
* Defect fix rate - Useful for projected completion
* Defects deferred


**Code size**

Code size is an important indicator of the areas where the team is spending the
most time on the project. Just by looking at the size of the code and the
different types of code will reveal a wealth of information that is useful for
managing the project.

For many languages, very sophisticated tools exist and are freely available. You
may want to investigate [sonarqube.org](http://www.sonarqube.org). This tool
counts the number of source code lines in different areas of your product. The
exact information is not important but the comparisons are extremely useful.

* Modules
* Functions
* Lines
* Documentation
* Tests

Compare these measurements to each other. Ask key business questions and let the
data reveal the answers:

* What percentage of the code is tests?
* What percentage of the code is documentation?
* How many functions per module?
* How long are my functions?
* How long are my tests?

As you begin to take measurements you will naturally begin to form ideas about
the proper rules for ideal code. Instead of being a pre-determined opinion about
the correct basic rules, it will be a well-informed opinion based on data.

Run the tools each day to ensure that the code is changing in a way that is
consistent with a healthy project direction. By creating plans that are tied to
actual code measurements you are leveraging the knowledge of your most
experienced engineers. You are also training your junior staff to rise to that
level.


**Complexity**

Another important area for measurement is code complexity. As we discussed in
chapter 6, Code Leverage, measuring the complexity of various parts of your
system is critical. This information needs to be fed back into the planning
process to generate the standards of complexity for a release criteria. If you
don't decide on this ahead of time the pressure to ship will undoubtedly
overwhelm the quality argument. This leads to releasing code that has an
unacceptable level of complexity and poor quality and will eventually turn into
a maintenance nightmare.

There are several different ways to study complexity. Create tools that capture
readings automatically and follow up on the advice they provide. Each of these
techniques provides a unique viewpoint into your system. Use the ones that make
the most sense to you.

* Points of interconnect
* Halstead & McCabe complexity measures
* Seaman's Complexity sum(lines ** 1.2)
* API language vocabulary
* Code Stability (%code change)


**Team Productivity**

A simple measure of productivity will allow you to see the impact of events
outside of your project. It is easy to put some simple measures in place. These
metrics can provide the key information you need when proposing project level
changes.

* Velocity (features / engineering day)
* Lines / day
* % of features / day
* Compare this project to similar projects


**Test Coverage**

We all believe that testing is important but it's good to compute the percentage
of effort related to tests compared to the product design. A product where
testing accounts for less than 10% of the code is in serious danger. Another
thing to watch at the project level is how many defects are repeat offenders.
This may indicate a failure in the regression testing methodology.

* lines of product / lines of test
* recidivism (repeated defects)


## Monitoring Tools

Measure all of the critical attributes of your system:

* Transactions/second
* Memory footprints
* Cache page-faults
* Max load conditions
* Concurrent users
* Disk space requirements
* Scalability requirements
* Developer productivity

Make a list of everything that is important to your application and take
measurements. This becomes the baseline for adequate performance of the system.
Any new system should create a demonstrable improvement on a number of these
metrics. Serious scrutiny should be given to any measure that drops. A hard look
is especially required before committing to any new technology.

---

## Best Practice #11 - _Monitor everything that you care about._


***Problem***<br>
Monitoring can produce a deep understanding of the operation of your software.
It can yield insight into which parts can be leveraged and how to get the
results you want. It can also teach you how to improve your development and
operations processes.

Monitoring covers a broad range of techniques that include: instrumentation,
logging, metrics collection, notifications, and dashboards. Together these
techniques build your system understanding and allow you to make strategic
improvements to your overall project. Neglecting monitoring will cause you to
rely on assumptions and folklore that will often be incorrect.

***Solution***<br>
Monitoring begins with systematically instrumenting your code. Log files can
reveal the history of your system at run time and let you write tools to analyze
this history. Logic can be added to your application to collect key metrics.
Dashboards and notifications call attention to key problem areas.

Each of these techniques will contribute to the quality of your products and
services by lowering the technical debt. These best practices in software 
engineering will preserve the value of your investment for years to come.

***Next Steps***

* Implement a consistent policy for logging in your source code.
* Select five key project metrics to begin measuring.
* Plan three experiments using measurements to validate assumptions.
* Research monitoring tools that are available from you hosting provider. 
* Begin developing standard rules about quantitative values for your key project
metrics.


