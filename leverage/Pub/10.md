# 10 - Application Deployment


> If you aren't embarrassed by the first version of your product, you've launched too late.
>
> ~ Reid Hoffman

---

## Versioning

Version control is critical to the entire deployment process. Without proper
management of the recipes for deployment, operations relies upon the staff to
faithfully remember every detail of how to keep the system running properly.
Humans aren't accurate enough at remembering a long series of detailed actions.
This makes computer automation critical for smooth operations.

Version control is absolutely essential to automation. Each time a set of tasks
is executed it must produce the exact same result. This requires writing
software for every task, encapsulating the entire history of actions. A version
control system must be used to allow explicit references to that history. You
should be able to retrace the exact steps of what happened last Tuesday at
10:00. Without this degree of rigor your operation will become extremely
unpredictable.

There are several good version control systems in widespread use. For the
purpose of this discussion I'll refer to all of these as Git. You should be
using a tool that has the same attributes as Git (such as Subversion, or 
Mercurial). 

If you need to manage binary content, git may be inadequate. You may want to
look at tools that are specifically set up to track binary content. Archiva,
Artifactory and Sonatype Nexus all integrate very well with Maven, Gradle, and
other build tools to download versioned binary tools. Artifact repositories are
a leverage enabler.

All automation should be built on top of Git. Control the server environments
and configurations by using branches. Merge branches together to manage the
project work-flow. Make sure that all of the deployment steps are built into
fully automatic tools. This will ensure that all deployment is done exactly the
same every time. This gives you a history that can be repeated to track down and
debug failures.


### Everything is Versioned

There are many types of files that must be versioned. It is important to
distinguish between the following items, all of which need to be tracked and
versioned:

* Source. This includes configuration templates or metadata
* Generated artifacts (from source). This needs to be versioned and stored in 
an artifact repository like Artifactory.
* Leveraged artifacts and tools. These also should come from a versioned 
artifact repository like Artifactory, which conveniently acts as a mirror of 
remote repositories
* Configuration files for our artifacts and leveraged artifacts. These are 
generally text files that are often generated on the fly by configuration 
management and deployment tools.


Proper use of Git requires that you truly understand the source code in your
project. There are many files that are combined together to create a product.
Some of these files are built during a build process. By definition, these are
not source code since they are built by you. Therefore, they should not be
managed within Git. Use *.gitignore* to skip over these files.

There are also tools that are required to build your project. Any tool that
will not be readily available (by version number) should be added to Git. Don't
take a chance at not being able to rebuild your product due to a missing tool. A
lot of the tools that we use help us set up and configure new machines. Any
files that are necessary for Configuration Management (CM) must be a part of the
source code for your project.

The specific versions of tools required to build your product should either be
tracked within your Git repository or available from some official source that
is guaranteed to be around two years from now, or as required by your company
policies. Make a conscious decision about these things rather than assume that
something will be there. Create reproducible results by tracking everything that
you need to build the entire world from scratch.
  

### Standard Branch Policy

Using branches within your Git repository can clarify many details related to 
work-flow. Throughout the development there are different uses for branches.

* Experiment with new ideas that may be incorporated later.
* Stage the integration of different pieces of code that rely on each other.
* Isolate responsibilities (eg. production, staging, test).
* Use branches to stabilize changes during releases.

It is important to have a solid branching policy. This helps all of the
engineers know how to work together in an effective manner. The first policy to
establish is how to slow down development close to a release so that
unintentional features or untested code is not accidentally released. A numbered
or named branch should be created for each major and minor release.

This allows the master branch to continue moving rapidly with lots of commits
while the release branches begin to be restricted.  Only changes that are
properly tested and reviewed are added to the release branch.  After the code
enters production the rate of change should slow even further.  Using a branch
allows some change to occur but this should be tightly controlled.

In addition to release branches, it is a good idea to use branches to establish
responsibilities for the work-flow. For example, Staging, Test, and Dev branches
can be used to mark code that is at different quality levels. As more testing is
applied the code is promoted to the next level by merging the branches together.
This lets you establish gateways or thresholds that must be passed in order to
go to the next level.

Branches are also used to experiment with ideas that aren't quite ready to put
into the mainstream development. These may be built around specific features or
used as integration branches for mutually dependent components that rely on each
other. It is best to integrate changes before they are merged into the master
branch.

![Git Branch Graph for Releases](img/Releases.png)


Requirements for release branches

* master is point of integration for new development
* stabilization branches slow rate of change
* release branches subdivide for each minor release
* release branches are often merged back into master


### Release Labeling

Branches capture a series of commits. Labels mark a single commit as being
significant. Every time the code changes in production it should have a label.
This lets you know exactly which version of code was in production at any given
time. Standardize the product labeling policy so that it remains stable over
time. Create a new label for each production version.

Example labeling strategy - Release 1.2.7.100

    1 - Major release
    1.2 - Minor release
    1.2.7 - Release number
    1.2.7.100 - Build #100 for 1.2.7 release

Note that this would be tracked by two branches (1 and 1.2). If you would
expect there to be multiple commits on 1.2.7 then you would add a third branch.
The head of each branch should be set to the most recent label that is applied.
For example, if labels "1.2.7.100" and "1.2.7.133" are used then the head of
1.2.7 branch would point to "1.2.7.133" label.


### Release Testing

A major part of the cost of releasing new software is related to the cost of
maintaining adequate test server environments. The test configurations should be
as close to the production environment as possible to provide a valid
indication that the code will function as expected in production. Maintaining
the testing environments can be a nightmare because the world is constantly
changing. All of the tricks that we have been discussing apply to maintaining
the test server setup.

As development proceeds, each commit is fully tested by using the automated
testing on each iteration. This gives us some confidence that the code is
working. Ultimately we need to deploy and test the code in a much more realistic
environment before we are ready to trust it enough for a production release.
This can be rather costly and involves configuring test servers that can do the
detailed testing. When the testing succeeds on the various test servers the code
is promoted to staging servers that are configured to be almost identical to the
production environment.

The code is then labeled and promoted into the production environment. As the
code begins to roll out through the production clusters, careful monitoring is
done to ensure a smooth roll. If anything unexpected crops up then a roll-back
is used to restore the previous state of the software.

An "After Action Review" should be done to study the results of the release. The
team should get together and discuss what happened and plan any changes that
should be made to the process before the next roll.

There is a minimum amount of effort required to fully test a release. There are
computational and staffing resources that must be applied. Rebuilding
environments or maintaining multiple environments is very expensive, even with
extensive use of configuration management and deployment tools. This creates a
minimum cost for the release cycle itself in addition to the cost of building
new functionality into the system. This is the single biggest reason why
organizations minimize releases and patches.

Measure this cost for your organization to determine the effort required for one
release. Discover the sweet spot for your testing and release cycle. Then
build your project release cycles to match your entire process.


## Continuous Integration

Delayed integration is costly; stay integrated as much as possible throughout
the development. The best way to do this is to make it impossible to submit code
that is not tested. As features are created new tests must also be created to
ensure that the features work properly and that they integrate with the other
code dependencies.

Tools can enforce the desired integration practices. Each time a commit is
attempted the code is automatically built, deployed, and tested. Only when all
the tests pass will the code be committed to the Git repository. This prevents
bad code from being committed. Of course, the effectiveness of this approach
hinges on the robustness of the tests that you write. Wimpy tests may still
allow bad code to be submitted.

Build tools, such as Archiva, Artifactory, Sonatype Nexus, Maven, and Gradle,
all assist in continuous integration through the setup and control of building
and testing code. Triggering these tools with each commit gives you a great
degree of confidence in the code.


### Use Tools to Enforce Integration 

There are several high-quality tools that make your job easier. They will
trigger a build/deploy/test cycle by bolting into Git. They allow rules to
customize the actions taken and produce notifications that keep you informed
about the progress.

Here's a list of tools for further investigation:

* Travis
* Jenkins
* AnthillPro
* Atlassian Bamboo
* Microsoft Team Foundation Server
* Drone

These tools require some energy to set up but can produce many times the benefit
on the first project cycle. Imagine the hours saved if you never had to track
down bad code that got committed through carelessness. Each time code is
committed to the master branch it initiates a testing cycle. Only code that
passes all tests is allowed. All other code is left for the developers to
properly debug.

Our projects may contain components that require different versions of the
target code to be built and tested. For example, we might need to produce
binaries to support multiple execution environments from the same source code.

* Different operating systems
* Different mobile devices
* Different product configurations
* Different server environments
* Different browsers

A tool such as Tox can be used to iterate over each environment and build,
deploy, and test the code. In order for Tox to pass, code must run properly in
all configurations and environments. The more elaborate environments require
dedicated servers for managing all of this testing. Over time you can build a
very robust test battery to cover everything that you truly care about.
  

### Automatic Integration

Integration is not a special step. If it is not viewed as a natural part of
development then it will be postponed. This will cause problems later on as
people begin to defer more and more of the integration work. Eventually
integration failures will block progress. By investing in tools for Continuous
Integration you will prevent this from happening.

Integration problems should be investigated as soon as they occur. If two pieces
of code should be working together and they aren't, this is a high priority for
debugging. This eliminates problems before they grow. New tests should be added
to address any system weaknesses that are uncovered.

Place the burden on each developer to get everything working properly rather
than some central staffing responsible for the build. If a developer makes an
error that causes problems for others it should be their responsibility to fix
it. Developer accountability is vital for the ongoing effectiveness of the
entire team. Use integration branches to assemble pieces of code that might take
several attempts to integrate. This protects everyone else's time. Some changes
need extra coordination and integration branches may be the best answer.

A counter-intuitive approach to automatic and continuous integration is to
make the development team, or individual, responsible for automating and
monitoring the state of the integration tests. In this scenario you trust your
teams to be entirely responsible for their product. They decide when it is
"good". Teams themselves build their integration environments (making generous
use of Docker or VMware workstation images, for example) on their development
stations. If you are not testing massive scale, this is how your organization
scales. For massive scale testing, you have a dedicated environment.


### Off-line Emergency Drills 

Practice emergency response skills. Conducting "fire drills" is a way to ensure
that everyone is prepared when the real thing happens. If you know that you must
deploy an application from scratch you should practice this drill as part of
your regular training regimen. Don't wait for the actual event to determine all
the tasks necessary to bring up and configure clusters of servers and get them
talking to each other.

You must have automation that goes from bare hardware requirements to running
applications. This process should stop just short of deployment on the
production servers. Practice setting up machines from scratch, data rollback,
and restoration.

Build in test hooks to your servers to allow you to observe critical aspects of
your running application. You may also benefit from special settings that are
applied only on your test configurations. These can prevent accidentally doing
actions that are only allowed on the production servers. Another approach is to
make certain additional features available for debugging only on the test
servers.

Be sure to provision dedicated servers for testing and staging. Don't try to
cut corners here. Your production environment should be fully disconnected from
your testing and staging environment.


## Configuration Management

Configuration Management is about defining the server execution environment. It
controls everything from the operating system version, application packages that
must be installed, configuration settings for each component, and network
configuration options for allowing the services to communicate with each other.
Everything about your system is controlled by your CM.

Automate server setup tasks completely. You should be able to go all the way
from your version control files and the hosting accounts to running applications
by using automated tools. Many smaller organizations use scripts to provide this
automation. Using leading edge tools can save a lot of work. These will generate
solutions quickly for the short term and provide greater capabilities as your
needs change.

You need repeatability in how your servers are configured. People make mistakes
and it is dangerous to rely on the knowledge of staff to understand how your
systems are configured. This must be fully automated and based on CM files to be
repeatable. Configuring machines properly is probably the hardest problem in
deployment and operations. The state of the art tools (Chef, Salt, ...) are very
hard to use and master. You need focused and/or dedicated resources to do this.
You can't make this a secondary priority for some new developer without
significant risk.


### Virtual Machine Setup

Virtualization is key to all modern software deployment. Vendors have given us
tools, such as Virtual Box and VMware, to build virtual machine images that
guide the configuration of new servers. Except for specialized applications with
special needs, apps are hosted on hardware that run many virtual machines
simultaneously. This has produced huge cost savings for the entire industry and
simplified operations.

Old applications were hosted directly on servers which meant that deployment
required setting up the hardware and configuring it to support the application
software that would run on it. This is now replaced with the challenge of
automating the machine configuration for the virtual image. The VM image is then
provisioned in the host environment so that the actual server can start serving
the task it was created for.

Creating new VM images can either be done manually by starting with an operating
system and building up the appropriate packages or by writing scripts that can
automate this process. Using CM tools can make the process of configuring new
VMs far more repeatable. It is also possible to write shell scripts that can
be used to install and setup all of the server configuration that you need.

Reusing virtual machine images is a key benefit of virtualization. If you need 
to create twenty servers with the same software you just create one virtual
machine image and instantiate it twenty times. This lets you create a template
for every new server while letting the servers have their own life cycle and 
data.


### Configurations

So what is in a configuration when we are preparing to use a configuration 
management tool? There are several key areas that need to be configured to
produce a new server instance.

* *settings* - Many different apps have settings that must be configured for the
app to run properly. It may require details of the host name, network topology,
or features to be enabled.

* *programs* - The software is typically a stack of programs rather than a
single program running on the server. Each of these programs must be installed
and configured properly. CM tools let you quickly install programs on top of the
basic operating system services.

* *users* - Modern applications often have groups of users and the corresponding
permissions granted to them. When creating a new server you may need an easy way
to bring in your user data to the new machine.

* *network* - The network information is an important part of the application.
You need to be able to assign network details such as domain name, host name,
network IP info, and security settings based on the situation.

* *services* - Your application is most likely a set of web services that 
coordinate with each other. There is some configuration information that 
governs the behavior of the interaction and collaboration of these services.


### Examples of CM Tools

***Puppet***  https://puppetlabs.com 

Puppet is an engine to help setup and configure machines and automate common
deployment tasks. "With Puppet, you define the state of your IT infrastructure,
and Puppet automatically enforces the desired state. Puppet automates every step
of the software delivery process, from provisioning of physical and virtual
machines to orchestration and reporting; from early-stage code development
through testing, production release and updates."


***Chef***  https://www.chef.io

"Chef is a company & configuration management tool written in Ruby and Erlang.
It uses a pure-Ruby, domain-specific language (DSL) for writing system
configuration "recipes". Chef is used to streamline the task of configuring and
maintaining a company's servers, and can integrate with cloud-based platforms
such as Rackspace, Internap, Amazon EC2, Google Cloud Platform, OpenStack,
SoftLayer, and Microsoft Azure to automatically provision and configure new
machines. Chef contains solutions for both small and large scale systems, with
features and pricing for the respective ranges."
https://en.wikipedia.org/wiki/Chef_(software)


***Ansible***  http://www.ansible.com/

"You need a consistent, reliable, and secure way to manage the environment - but
many solutions have gone way too far the other direction, actually adding 
complexity to an already complicated problem. You need a system that builds on
existing concepts you already understand and doesn't require a large team of
developers to maintain."


***Salt***  http://saltstack.com 

"SaltStack software orchestrates the build and ongoing management of any legacy
or modern infrastructure. SaltStack is known as the fastest, most scalable
systems and configuration management software for event-driven automation of
CloudOps, ITOps and DevOps."


### Lightweight Virtualization Using Docker

Recently there is a new paradigm for creating the execution environment for
software. Lightweight virtualization has some significant advantages over
traditional virtualization techniques. A virtual machine abstracts the hardware
so that software written for any operating system can run. This means that each
virtual machine must carry the full operating system inside each VM. Lightweight
virtualization is built on abstracting a set of software services so that
software can be deployed in a much smaller container.


Benefits of Lightweight Virtualization

* Application containers are much smaller than virtual machines
* Containers load faster
* More containers can be hosted on one hardware server
* Every container holds all software dependencies with explicit versions
* Containers are portable between hosting providers
* All major public cloud providers are producing provisioning tools
* Software is built on a fixed standard operating system layer
* Tools allow you to go from development to production with the same execution environment


Many containers that are hosted on a machine will all share the same instance of
the operating system kernel. This has huge impact on the number of containers
that can be run on a given machine. The start up time for the service is greatly
reduced since there is no need to load the kernel. The overall system load that
a container produces is far less than a virtual machine.


_Docker is a platform for developers and system administrators to develop, ship,
and run applications. Docker lets you quickly assemble applications from
components and eliminates the friction that can come when shipping code. Docker
lets you get your code tested and deployed into production as fast as possible.

Excerpt from http://docker.com_


One of the best new technologies for lightweight virtualization is Docker, which
was introduced at PyCon in 2013. Since that time it has received a great deal of
attention because it offers real answers to many pressing questions. I believe
that Docker represents the future of software deployment. Time will tell, but
Docker may emerge as the best answer for packaging, distributing, and running
apps.

There are several core concepts that Docker uses. Here is a minimal introduction
to the vocabulary. For more information visit the Docker website at
http://docker.com.

* *Container* - A container provides a minimalistic version of a Linux operating
system that gives your app a run-time execution context. Starting up a service
process involves loading an image and starting the container.

* *Docker Image* - An image is software you load into a container. An image 
has all of the required dependencies configured to run the required service.
Images can be stored for later execution or extension.

* *Docker File* - Images are constructed from other images by following the
recipe within a Docker File. Therefore, the Docker File is like a build script
for Images. It provides configuration instructions for an image instance.

* *Docker Hub* - A web service (like Git Hub) lets you find and share Docker
Images from others. This creates an entire ecosystem for collaboration.

Containers bundle all the required dependencies for an app. Loading an image
into a container sets up access to all of the dependencies. It should be as
simple and small as possible to startup fast. Images are the template for
instantiating new containers. Repositories allow you to share images with others
and there is a public repository called Docker Hub. Docker file is the recipe to
configure an image. Often new images are built on existing images that already
have most of the dependencies that are needed. The developer only needs to add
new requirements.


## Provisioning Servers

Large applications require clusters of computers that are collaborating
together. Orchestration is the task of managing all of the different servers
that are running. As the load climbs you may need to provision new services of
a specific type.

Tools automate the startup, shutdown, and monitoring of running servers. All of
the major cloud service providers offer extensive tooling for managing your
services. They support automatic rules for when to add new services and when to
reduce the server pool. They also give you tools for monitoring many different
aspects of your operation in real-time.

Hosting vendors typically provide tools specific to them. Spend time learning
the tools that are related to your cloud provider. Experiment with the options
for the specific scenarios that you are most interested in. As you scale your
system load, the key bottlenecks are likely to move. Perform experiments to
create scenarios that are typical of what you will encounter.


### Clusters of Dependent Systems

There are different types of servers that will be important in your operation.
Make sure that you have solutions that are appropriate for the real challenges
that your business faces. The architecture that controls these server
interaction is also very important.

* *load balancers* - manage rules for routing the requests to other servers

* *web servers* - map HTTP requests into HTTP responses

* *application servers* - business logic for your app

* *databases* - relational or No SQL services provide persistence

* *caching* - remember and offer responses to speed up throughput

Each type of server may have multiple instances running. A cluster of servers
may be used to handle all of the required traffic. Tools will let you manage the
number of servers that are running and provide rules by which new servers are
started or shutdown.

In a complex production environment rolling updates are typically done to deploy
new software. There may be hundreds of servers running and it is not practical
to upgrade all of them at once. What usually happens is new servers are brought
online that contain the new software and are meant to coexist with the old
system. The old and new software will both run for a while together, but
eventually the old servers will be shutdown, leaving only the new software to
handle the incoming requests.


### System Setup with Provisioning Tools

Leverage can be applied to how we manage operations. The established policies
and processes can be reused and applied on each new release for a period of
year. But for this to occur, our operations must have three characteristics.
Automated, Dynamic, and Autonomous systems support the leverage you need.

* *Automated* - Situations must be automated and managed by scripts rather than
by staff knowledge enacted manually.

* *Dynamic* - The automation must be dynamic and anticipate a broad range of new
circumstances. Rules should dictate the resources applied to meet the existing
demand.

* *Autonomous* - Systems should be autonomous, running independently until
attention is needed to fix a problem.

Business rules should control the Computing Resources and Storage Resources that
are applied to address the current load. A simple configuration setting should
give you the control necessary to manage the fluctuating demand for your apps.

Another point of leverage that should be evaluated is the degree to which you
need cloud portability. Are you locked into your existing cloud service
provider? Do you have the flexibility to move between providers if needed? This
is often dependent on the tools that you use to manage your operations. To
minimize vendor lock-in you should lean more heavily upon tools and technology
that support that provide portability.



## Best Practice #10 - _Automate everything except the decision to deploy._


***Problem***<br>
Operations frequently depend on the knowledge of specific staff members. The 
loss of a single individual can often threaten the entire operation. Processes
that rely on people are not easily repeatable, and will limit the amount of 
leverage that is possible in your operations.

Virtual machines are typically used to deploy applications for customer use. It
can be a significant task to get new VMs properly configured and provisioned.
Without a proper set of servers and automated scripts, deployment can be messy
and painful. All configuration information must be managed under version control
because it is an integral part of the software.

***Solution***<br>
Using configuration management tools can drastically simplify the setup of new
machines. These tools produce settings that can be committed to version control
and applied with repeatable results.

Deployment should be practiced on staging and testing servers in preparation for
a scheduled update to the production servers. The process of building and
provisioning new servers must be managed by automatic scripts. Docker provides a
new model of lightweight virtualization that makes it easy to move code from
development into production. Large commitments are being made by public cloud
providers to make it an effective solution for future deployment.

***Next Steps***

* Evaluate the number of clicks required to create new VM Images.
* Evaluate your process for managing active resources based on current load.
* Investigate Docker as a deployment alternative.
* Develop a block diagram of server types and how they are managed.

